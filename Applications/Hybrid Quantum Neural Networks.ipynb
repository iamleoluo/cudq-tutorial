{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the relevant packages.\n",
    "\n",
    "! pip install numpy==1.24.4 matplotlib==3.8.4 torch==2.0.1+cu118 torchvision==0.15.2+cu118 scikit-learn==1.4.2 -q --extra-index-url https://download.pytorch.org/whl/cu126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant libraries\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import cudaq\n",
    "from cudaq import spin\n",
    "\n",
    "torch.manual_seed(22)\n",
    "cudaq.set_random_seed(44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set CUDAQ and PyTorch to run on either CPU or GPU.\n",
    "\n",
    "#device = torch.device('cpu')\n",
    "#cudaq.set_target(\"qpp-cpu\")\n",
    "\n",
    "cudaq.set_target(\"tensornet\")\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(target_digits, sample_count, test_size):\n",
    "    \"\"\"Load and prepare the MNIST dataset to be used\n",
    "\n",
    "    Args:\n",
    "        target_digits (list): digits to perform classification of\n",
    "        sample_count (int): total number of images to be used\n",
    "        test_size (float): percentage of sample_count to be used as test set, the remainder is the training set\n",
    "\n",
    "    Returns:\n",
    "        dataset in train, test format with targets\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.1307), (0.3081))])\n",
    "\n",
    "    dataset = datasets.MNIST(\"./data\",\n",
    "                             train=True,\n",
    "                             download=True,\n",
    "                             transform=transform)\n",
    "\n",
    "    # Filter out the required labels.\n",
    "    idx = (dataset.targets == target_digits[0]) | (dataset.targets\n",
    "                                                   == target_digits[1])\n",
    "    dataset.data = dataset.data[idx]\n",
    "    dataset.targets = dataset.targets[idx]\n",
    "\n",
    "    # Select a subset based on number of datapoints specified by sample_count.\n",
    "    subset_indices = torch.randperm(dataset.data.size(0))[:sample_count]\n",
    "\n",
    "    x = dataset.data[subset_indices].float().unsqueeze(1).to(device)\n",
    "\n",
    "    y = dataset.targets[subset_indices].to(device).float().to(device)\n",
    "\n",
    "    # Relabel the targets as a 0 or a 1.\n",
    "    y = torch.where(y == min(target_digits), 0.0, 1.0)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,\n",
    "                                                        y,\n",
    "                                                        test_size=test_size /\n",
    "                                                        100,\n",
    "                                                        shuffle=True,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classical parameters.\n",
    "\n",
    "sample_count = 1000  # Total number of images to use.\n",
    "target_digits = [5, 6]  # Hand written digits to classify.\n",
    "test_size = 30  # Percentage of dataset to be used for testing.\n",
    "classification_threshold = 0.5  # Classification boundary used to measure accuracy.\n",
    "epochs = 2  # Number of epochs to train for.\n",
    "\n",
    "# Quantum parmeters.\n",
    "\n",
    "qubit_count = 1  # Number of qubits to use.\n",
    "hamiltonian = spin.z(0)  # Measurement operator.\n",
    "shift = torch.tensor(torch.pi / 2)  # Magnitude of parameter shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = prepare_data(target_digits, sample_count,test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some images from the training set to visualise.\n",
    "if device != 'cpu':\n",
    "    sample_to_plot = x_train[:10].to(torch.device('cpu'))\n",
    "else:\n",
    "    sample_to_plot = x_train[:10]\n",
    "\n",
    "grid_img = torchvision.utils.make_grid(sample_to_plot,\n",
    "                                       nrow=5,\n",
    "                                       padding=3,\n",
    "                                       normalize=True)\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumFunction(Function):\n",
    "    \"\"\"Allows the quantum circuit to input data, output expectation values\n",
    "    and calculate gradients of variational parameters via finite difference\"\"\"\n",
    "\n",
    "    def __init__(self, qubit_count: int, hamiltonian: cudaq.SpinOperator):\n",
    "        \"\"\"Define the quantum circuit in CUDA Quantum\"\"\"\n",
    "\n",
    "        @cudaq.kernel\n",
    "        def kernel(qubit_count: int, thetas: np.ndarray):\n",
    "\n",
    "            qubits = cudaq.qvector(qubit_count)\n",
    "\n",
    "            ry(thetas[0], qubits[0])\n",
    "            rx(thetas[1], qubits[0])\n",
    "\n",
    "        self.kernel = kernel\n",
    "        self.qubit_count = qubit_count\n",
    "        self.hamiltonian = hamiltonian\n",
    "\n",
    "    def run(self, theta_vals: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"Excetute the quantum circuit to output an expectation value\"\"\"\n",
    "\n",
    "        #If running on GPU, thetas is a torch.tensor that will live on GPU memory. The observe function calls a .tolist() method on icputs which moves thetas from GPU to CPU.\n",
    "\n",
    "        qubit_count = [self.qubit_count for _ in range(theta_vals.shape[0])]\n",
    "\n",
    "        results = cudaq.observe(self.kernel, self.hamiltonian, qubit_count,\n",
    "                                theta_vals)\n",
    "\n",
    "        exp_vals = [results[i].expectation() for i in range(len(results))]\n",
    "        exp_vals = torch.Tensor(exp_vals).to(device)\n",
    "\n",
    "        return exp_vals\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, thetas: torch.tensor, quantum_circuit,\n",
    "                shift) -> torch.tensor:\n",
    "\n",
    "        # Save shift and quantum_circuit in context to use in backward.\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        # Calculate expectation value.\n",
    "        exp_vals = ctx.quantum_circuit.run(thetas).reshape(-1, 1)\n",
    "\n",
    "        ctx.save_for_backward(thetas, exp_vals)\n",
    "\n",
    "        return exp_vals\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"Backward pass computation via finite difference\"\"\"\n",
    "\n",
    "        thetas, _ = ctx.saved_tensors\n",
    "\n",
    "        gradients = torch.zeros(thetas.shape, device=device)\n",
    "\n",
    "        for i in range(thetas.shape[1]):\n",
    "\n",
    "            thetas_plus = thetas.clone()\n",
    "            thetas_plus[:, i] += ctx.shift\n",
    "            exp_vals_plus = ctx.quantum_circuit.run(thetas_plus)\n",
    "\n",
    "            thetas_minus = thetas.clone()\n",
    "            thetas_minus[:, i] -= ctx.shift\n",
    "            exp_vals_minus = ctx.quantum_circuit.run(thetas_minus)\n",
    "\n",
    "            gradients[:, i] = (exp_vals_plus - exp_vals_minus) / (2 * ctx.shift)\n",
    "\n",
    "        gradients = torch.mul(grad_output, gradients)\n",
    "\n",
    "        return gradients, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumLayer(nn.Module):\n",
    "    \"\"\"Encapsulates a quantum circuit into a quantum layer adhering PyTorch convention\"\"\"\n",
    "\n",
    "    def __init__(self, qubit_count: int, hamiltonian, shift: torch.tensor):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "\n",
    "        self.quantum_circuit = QuantumFunction(qubit_count, hamiltonian)\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, input):\n",
    "\n",
    "        result = QuantumFunction.apply(input, self.quantum_circuit, self.shift)\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hybrid_QNN(nn.Module):\n",
    "    \"\"\"Structure of the hybrid neural network with classical fully connected layers and quantum layers\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Hybrid_QNN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.fc5 = nn.Linear(32, 2)\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "\n",
    "        # The 2 outputs from PyTorch fc5 layer feed into the 2 variational gates in the quantum circuit.\n",
    "        self.quantum = QuantumLayer(qubit_count, hamiltonian, shift)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(-1, 28 * 28)  # Turns images into vectors.\n",
    "\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Quantum circuit outputs an expectation value which is fed into the sigmoid activation function to perform classification.\n",
    "        x = torch.sigmoid(self.quantum(x))\n",
    "\n",
    "        return x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y, y_hat, classification_threshold=0.5):\n",
    "    # Compute accuracy directly on the GPU\n",
    "    correct = (y == (y_hat >= classification_threshold)).float().sum()\n",
    "    accuracy = correct / y.size(0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "\n",
    "\n",
    "class HybridTrainer:\n",
    "    def __init__(self, model, optimizer, loss_function, writer, device):\n",
    "        \"\"\"\n",
    "        Initializes the trainer class.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): The PyTorch model to train and evaluate.\n",
    "            optimizer (torch.optim.Optimizer): The optimizer for training.\n",
    "            loss_function (torch.nn.Module): The loss function.\n",
    "            writer (SummaryWriter): TensorBoard SummaryWriter instance.\n",
    "            device (torch.device): Device to run the computations on (e.g., 'cpu' or 'cuda').\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_function = loss_function\n",
    "        self.writer = writer\n",
    "        self.device = device\n",
    "\n",
    "        self.training_cost = []\n",
    "        self.testing_cost = []\n",
    "        self.training_accuracy = []\n",
    "        self.testing_accuracy = []\n",
    "\n",
    "    def train(self, x_train, y_train, epoch):\n",
    "        \"\"\"\n",
    "        Runs one epoch of training and logs metrics.\n",
    "\n",
    "        Args:\n",
    "            x_train (torch.Tensor): Training data.\n",
    "            y_train (torch.Tensor): Training labels.\n",
    "            epoch (int): Current epoch index.\n",
    "        \"\"\"\n",
    "        train_start_time = time.time()\n",
    "\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_hat_train = self.model(x_train).to(self.device)\n",
    "        train_cost = self.loss_function(y_hat_train, y_train).to(self.device)\n",
    "\n",
    "        # Backward pass\n",
    "        train_cost.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = accuracy_score(y_train, y_hat_train)\n",
    "        self.training_accuracy.append(accuracy)\n",
    "        self.training_cost.append(train_cost.item())\n",
    "\n",
    "        # Log training time\n",
    "        train_elapsed_time = time.time() - train_start_time\n",
    "        self.writer.add_scalar(\"Time(s) per epoch/Train\", train_elapsed_time, epoch + 1)\n",
    "\n",
    "        # Log training metrics to TensorBoard\n",
    "        self.writer.add_scalar(\"Loss/Train\", train_cost.item(), epoch + 1)\n",
    "        self.writer.add_scalar(\"Accuracy/Train\", accuracy, epoch + 1)\n",
    "    def test(self, x_test, y_test, epoch):\n",
    "        \"\"\"\n",
    "        Runs one evaluation step and logs metrics.\n",
    "\n",
    "        Args:\n",
    "            x_test (torch.Tensor): Testing data.\n",
    "            y_test (torch.Tensor): Testing labels.\n",
    "            epoch (int): Current epoch index.\n",
    "        \"\"\"\n",
    "        eval_start_time = time.time()\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Forward pass\n",
    "            y_hat_test = self.model(x_test).to(self.device)\n",
    "            test_cost = self.loss_function(y_hat_test, y_test).to(self.device)\n",
    "\n",
    "            # Compute accuracy\n",
    "            accuracy = accuracy_score(y_test, y_hat_test)\n",
    "            self.testing_accuracy.append(accuracy)\n",
    "            self.testing_cost.append(test_cost.item())\n",
    "\n",
    "            # Log evaluation time\n",
    "            eval_elapsed_time = time.time() - eval_start_time\n",
    "            self.writer.add_scalar(\"Time(s) per epoch/Eval\", eval_elapsed_time, epoch + 1)\n",
    "\n",
    "            # Log testing metrics to TensorBoard\n",
    "            self.writer.add_scalar(\"Loss/Test\", test_cost.item(), epoch + 1)\n",
    "            self.writer.add_scalar(\"Accuracy/Test\", accuracy, epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Generate a unique log directory with timestamp\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f\"./runs/hybrid_qnn_training_{current_time}\"\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# Initialize the trainer with your model, optimizer, loss function, etc.\n",
    "hybrid_model = Hybrid_QNN().to(device)\n",
    "trainer = HybridTrainer(\n",
    "    model=hybrid_model,\n",
    "    optimizer=optim.Adadelta(hybrid_model.parameters(), lr=0.001, weight_decay=0.8),\n",
    "    loss_function=nn.BCELoss().to(device),\n",
    "    writer=writer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 Training done.\n",
      "Testing done.\n",
      "Epoch 2/2 Training done.\n",
      "Testing done.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    # Call the train and test methods for each epoch\n",
    "    trainer.train(x_train, y_train, epoch)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} Training done.\")\n",
    "    trainer.test(x_test, y_test, epoch)\n",
    "    print(f\"Testing done.\")\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from torch.utils.tensorboard import SummaryWriter\\n\\n# Initialize TensorBoard writer\\nwriter = SummaryWriter(log_dir=\"./runs/hybrid_qnn_training\")\\n\\n# Existing code\\nhybrid_model = Hybrid_QNN().to(device)\\n\\noptimizer = optim.Adadelta(hybrid_model.parameters(),\\n                           lr=0.001,\\n                           weight_decay=0.8)\\n\\nloss_function = nn.BCELoss().to(device)\\n\\ntraining_cost = []\\ntesting_cost = []\\ntraining_accuracy = []\\ntesting_accuracy = []\\n\\nhybrid_model.train()\\n\\n\\nimport time\\nfor epoch in range(epochs):\\n\\n    train_start_time = time.time()\\n\\n    optimizer.zero_grad()\\n\\n    y_hat_train = hybrid_model(x_train).to(device)\\n\\n    train_cost = loss_function(y_hat_train, y_train).to(device)\\n\\n    train_cost.backward()\\n\\n    optimizer.step()\\n\\n    training_accuracy.append(accuracy_score(y_train, y_hat_train))\\n    training_cost.append(train_cost.item())\\n\\n    train_elapsed_time = time.time() - train_start_time\\n    writer.add_scalar(\"Time/Train\", train_elapsed_time, epoch + 1)\\n\\n    writer.add_scalar(\"Loss/Train\", train_cost.item(), epoch + 1)\\n    writer.add_scalar(\"Accuracy/Train\", training_accuracy[-1], epoch + 1)\\n\\n    eval_start_time = time.time()\\n\\n    hybrid_model.eval()\\n    with torch.no_grad():\\n\\n        y_hat_test = hybrid_model(x_test).to(device)\\n\\n        test_cost = loss_function(y_hat_test, y_test).to(device)\\n\\n        testing_accuracy.append(accuracy_score(y_test, y_hat_test))\\n        testing_cost.append(test_cost.item())\\n\\n\\n        # Log testing metrics to TensorBoard\\n        writer.add_scalar(\"Loss/Test\", test_cost.item(), epoch + 1)\\n        writer.add_scalar(\"Accuracy/Test\", testing_accuracy[-1], epoch + 1)\\n\\n# Close TensorBoard writer\\nwriter.close()'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter(log_dir=\"./runs/hybrid_qnn_training\")\n",
    "\n",
    "# Existing code\n",
    "hybrid_model = Hybrid_QNN().to(device)\n",
    "\n",
    "optimizer = optim.Adadelta(hybrid_model.parameters(),\n",
    "                           lr=0.001,\n",
    "                           weight_decay=0.8)\n",
    "\n",
    "loss_function = nn.BCELoss().to(device)\n",
    "\n",
    "training_cost = []\n",
    "testing_cost = []\n",
    "training_accuracy = []\n",
    "testing_accuracy = []\n",
    "\n",
    "hybrid_model.train()\n",
    "\n",
    "\n",
    "import time\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    y_hat_train = hybrid_model(x_train).to(device)\n",
    "\n",
    "    train_cost = loss_function(y_hat_train, y_train).to(device)\n",
    "\n",
    "    train_cost.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    training_accuracy.append(accuracy_score(y_train, y_hat_train))\n",
    "    training_cost.append(train_cost.item())\n",
    "\n",
    "    train_elapsed_time = time.time() - train_start_time\n",
    "    writer.add_scalar(\"Time/Train\", train_elapsed_time, epoch + 1)\n",
    "\n",
    "    writer.add_scalar(\"Loss/Train\", train_cost.item(), epoch + 1)\n",
    "    writer.add_scalar(\"Accuracy/Train\", training_accuracy[-1], epoch + 1)\n",
    "\n",
    "    eval_start_time = time.time()\n",
    "\n",
    "    hybrid_model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        y_hat_test = hybrid_model(x_test).to(device)\n",
    "\n",
    "        test_cost = loss_function(y_hat_test, y_test).to(device)\n",
    "\n",
    "        testing_accuracy.append(accuracy_score(y_test, y_hat_test))\n",
    "        testing_cost.append(test_cost.item())\n",
    "\n",
    "\n",
    "        # Log testing metrics to TensorBoard\n",
    "        writer.add_scalar(\"Loss/Test\", test_cost.item(), epoch + 1)\n",
    "        writer.add_scalar(\"Accuracy/Test\", testing_accuracy[-1], epoch + 1)\n",
    "\n",
    "# Close TensorBoard writer\n",
    "writer.close()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_cost' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtraining_cost\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(testing_cost, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_cost' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(training_cost, label='Train')\n",
    "plt.plot(testing_cost, label='Test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cost')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "training_accuracy = np.array(torch.tensor(training_accuracy).cpu())\n",
    "testing_accuracy = np.array(torch.tensor(testing_accuracy).cpu())\n",
    "plt.plot(training_accuracy, label='Train')\n",
    "plt.plot(testing_accuracy, label='Test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyperquantum-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
